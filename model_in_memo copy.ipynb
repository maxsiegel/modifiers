{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read in files\n",
    "# Read UK_df.csv as pandas dataframe\n",
    "original_UK_dialogue = pd.read_csv('UK_df.csv')\n",
    "original_UK_politeness = pd.read_csv('UK_direct_df.csv')\n",
    "original_UK_narrator = pd.read_csv('UK_narrator_df.csv')\n",
    "original_US_dialogue = pd.read_csv('US_df.csv')\n",
    "original_US_politeness = pd.read_csv('US_direct_df.csv')\n",
    "original_US_narrator = pd.read_csv('US_narrator_df.csv')\n",
    "dataframes = [original_UK_dialogue, original_UK_politeness, original_UK_narrator, original_US_dialogue, original_US_politeness, original_US_narrator]\n",
    "def elim_outliers(df):\n",
    "    # dropped Unnamed: 0 column\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    filtered_df = df.loc[(df['response'] > 95) | (df['response'] < 5)]\n",
    "    for id in df['person_id'].unique():\n",
    "        if len(filtered_df[filtered_df['person_id'] == id])/len(df[df['person_id'] == id])>0.8:\n",
    "            df.drop(df[df['person_id'] == id].index, inplace=True)\n",
    "    df['predicate Z-score'] = df.groupby(['person_id','predicate'])['response'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "    # if has_intensifier = no then change 'intensifier' to 'none'\n",
    "    df.loc[df['has intensifier?'] == 'no', 'intensifier'] = 'none'\n",
    "    return df\n",
    "for i in range(len(dataframes)):\n",
    "    dataframes[i] = elim_outliers(dataframes[i])\n",
    "dialogue = pd.concat([dataframes[0], dataframes[3]])\n",
    "politeness = pd.concat([dataframes[1], dataframes[4]])\n",
    "UK_dialogue = dataframes[0]\n",
    "US_dialogue = dataframes[3]\n",
    "UK_politeness = dataframes[1]\n",
    "US_politeness = dataframes[4]\n",
    "\n",
    "# end of reading in data\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# compute U_soc (social Utility)\n",
    "U_soc_data = politeness.groupby(['intensifier','predicate'])['predicate Z-score'].mean().to_dict()\n",
    "UK_U_soc_data = UK_politeness.groupby(['intensifier','predicate'])['predicate Z-score'].mean().to_dict()\n",
    "US_U_soc_data = US_politeness.groupby(['intensifier','predicate'])['predicate Z-score'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memo import memo\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from enum import IntEnum, auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "infty = 10000000\n",
    "utterences =list(U_soc_data.keys())\n",
    "state_values = np.linspace(-2.8,2.8,20)\n",
    "S = np.arange(0,20,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params to iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.linspace(0,4,4)\n",
    "possible_soc_terms = np.linspace(0,3,5)\n",
    "possible_inf_terms = np.linspace(0,3,5)\n",
    "theta_to_test = np.arange(0,20,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search (code from demo-rsa.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W(IntEnum):  # utterance space\n",
    "    # borings\n",
    "    none_boring = auto(0)\n",
    "    slightly_boring = auto()\n",
    "    kind_of_boring = auto()\n",
    "    quite_boring = auto()\n",
    "    very_boring = auto()\n",
    "    extremely_boring = auto()\n",
    "    # concerneds\n",
    "    none_concerned = auto()\n",
    "    slightly_concerned = auto()\n",
    "    kind_of_concerned = auto()\n",
    "    quite_concerned = auto()\n",
    "    very_concerned = auto()\n",
    "    extremely_concerned = auto()\n",
    "    # difficults\n",
    "    none_difficult = auto()\n",
    "    slightly_difficult = auto()\n",
    "    kind_of_difficult = auto()\n",
    "    quite_difficult = auto()\n",
    "    very_difficult = auto()\n",
    "    extremely_difficult = auto()\n",
    "    # exhausteds\n",
    "    none_exhausted = auto()\n",
    "    slightly_exhausted = auto()\n",
    "    kind_of_exhausted = auto()\n",
    "    quite_exhausted = auto()\n",
    "    very_exhausted = auto()\n",
    "    extremely_exhausted = auto()\n",
    "    # helpfuls\n",
    "    none_helpful = auto()\n",
    "    slightly_helpful = auto()\n",
    "    kind_of_helpful = auto()\n",
    "    quite_helpful = auto()\n",
    "    very_helpful = auto()\n",
    "    extremely_helpful = auto()\n",
    "    # impressives\n",
    "    none_impressive = auto()\n",
    "    slightly_impressive = auto()\n",
    "    kind_of_impressive = auto()\n",
    "    quite_impressive = auto()\n",
    "    very_impressive = auto()\n",
    "    extremely_impressive = auto()\n",
    "    # understandables\n",
    "    none_understandable = auto()\n",
    "    slightly_understandable = auto()\n",
    "    kind_of_understandable = auto()\n",
    "    quite_understandable = auto()\n",
    "    very_understandable = auto()\n",
    "    extremely_understandable = auto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the mapping dictionary\n",
    "U_soc_key_map = {w: (' '.join(w.name.split('_')[:-1]), w.name.split('_')[-1]) for w in W}\n",
    "U_soc_array = np.array([U_soc_data[U_soc_key_map[W(i)]] for i in range(len(W))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct measured_values which is an array of 42 arrays where the i'th entry is the values people reported for the i'th utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_literal_semantics = np.array(\n",
    "    [\n",
    "        np.concatenate([np.repeat(np.array([epsilon]),i),np.repeat(np.array([1]),20-i)])\n",
    "        for i in range(20)\n",
    "    ]\n",
    ")\n",
    "@jax.jit\n",
    "def state_prior(s):\n",
    "    return np.float32(np.exp(-state_values[s]**2/2))  # uninformative state prior doesn't matter that it doesn't add up to 1\n",
    "@jax.jit\n",
    "def U_soc(soc):\n",
    "    return U_soc_array[soc]\n",
    "@jax.jit\n",
    "def is_costly(w):\n",
    "    arr = [0, 1, 1, 1, 1, 1]*7\n",
    "    return np.array(arr)[w]\n",
    "@jax.jit\n",
    "def L(w, s,t0,t1,t2,t3,t4,t5):  # literal likelihood L(w | s)\n",
    "    intensifier_semantics = np.array([  # \"hard semantics\"\n",
    "        possible_literal_semantics[t0],  # none\n",
    "        possible_literal_semantics[t1],  # slightly \n",
    "        possible_literal_semantics[t2],  # kind of\n",
    "        possible_literal_semantics[t3],  # quite\n",
    "        possible_literal_semantics[t4],  # very\n",
    "        possible_literal_semantics[t5],  # extremely\n",
    "    ])\n",
    "    return np.tile(intensifier_semantics, (7, 1))[w, s]\n",
    "@memo\n",
    "def L1[s: S, w: W](inf_term, soc_term, cost,t0,t1,t2,t3,t4,t5):\n",
    "    listener: thinks[\n",
    "        speaker: given(s in S, wpp=state_prior(s)),\n",
    "        speaker: thinks[\n",
    "            listener: thinks[\n",
    "                speaker: given(s in S, wpp=state_prior(s)),\n",
    "                speaker: chooses(w in W, wpp=L(w, s,t0,t1,t2,t3,t4,t5))\n",
    "            ]\n",
    "        ],\n",
    "        speaker: chooses(w in W, wpp=exp( imagine[\n",
    "            listener: observes [speaker.w] is w,\n",
    "            listener: knows(s),\n",
    "            (\n",
    "                inf_term * listener[ log(Pr[speaker.s == s]) ] +  # U_inf = listener's surprisal\n",
    "                soc_term * U_soc(w) - # U_soc = listener's EU\n",
    "                cost*is_costly(w)  # cost of utterance\n",
    "            )\n",
    "        ]))\n",
    "    ]\n",
    "    listener: observes[speaker.w] is w\n",
    "    listener: chooses(s in S, wpp=Pr[speaker.s == s])\n",
    "    return Pr[listener.s == s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of JAX arrays\n",
    "measured_values = []\n",
    "for w in W:\n",
    "    intensifier, predicate = U_soc_key_map[w]   \n",
    "    raw_values = UK_dialogue[((UK_dialogue['intensifier'] == intensifier) & (UK_dialogue['predicate'] == predicate))]['predicate Z-score'].values\n",
    "    # measured_values.append(np.array([int(r/0.28)+10 for r in raw_values]))\n",
    "    z = [int(r/0.28)+10 for r in raw_values]\n",
    "    x = [0]*len(S)\n",
    "    for i in z:\n",
    "        x[i] += 1\n",
    "    measured_values.append(x)\n",
    "measured_values = np.array(measured_values)\n",
    "def compute_logloss(*params):\n",
    "    thetas = params[:6]\n",
    "    cost = params[6]\n",
    "    inf_term = params[7]\n",
    "    soc_term = params[8]\n",
    "    # compute fit e.g. log_likelihood\n",
    "    P_l1 = L1(inf_term=inf_term, soc_term=soc_term, cost=cost, t0 = thetas[0],t1=thetas[1], t2= thetas[2], t3 = thetas[3], t4 = thetas[4], t5 = thetas[5]) # note this should be P(s|w)\n",
    "    return np.sum(np.log(P_l1)*measured_values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_param_combos = len(costs)*len(possible_soc_terms)*len(possible_inf_terms)*len(theta_to_test)**3\n",
    "in_repeat = total_param_combos//len(theta_to_test)\n",
    "out_repeat = 1\n",
    "# first_thetas = np.repeat(np.tile(theta_to_test, in_repeat),out_repeat)\n",
    "# out_repeat = out_repeat*len(theta_to_test)\n",
    "# in_repeat = in_repeat//len(theta_to_test)\n",
    "# second_thetas = np.repeat(np.tile(theta_to_test, in_repeat),out_repeat)\n",
    "# out_repeat = out_repeat*len(theta_to_test)\n",
    "# in_repeat = in_repeat//len(theta_to_test)\n",
    "# third_thetas = np.repeat(np.tile(theta_to_test, in_repeat),out_repeat)\n",
    "# out_repeat = out_repeat*len(theta_to_test)\n",
    "# in_repeat = in_repeat//len(theta_to_test)\n",
    "fourth_thetas = np.repeat(np.tile(theta_to_test, in_repeat),out_repeat)\n",
    "out_repeat = out_repeat*len(theta_to_test)\n",
    "in_repeat = in_repeat//len(theta_to_test)\n",
    "fifth_thetas = np.repeat(np.tile(theta_to_test, in_repeat),out_repeat)\n",
    "out_repeat = out_repeat*len(theta_to_test)\n",
    "in_repeat = in_repeat//len(theta_to_test)\n",
    "sixth_thetas = np.repeat(np.tile(theta_to_test, in_repeat),out_repeat)\n",
    "out_repeat = out_repeat*len(theta_to_test)\n",
    "in_repeat = in_repeat//len(costs)\n",
    "seventh_costs = np.repeat(np.tile(costs, in_repeat),out_repeat)\n",
    "out_repeat = out_repeat*len(costs)\n",
    "in_repeat = in_repeat//len(possible_inf_terms)\n",
    "eighth_infs = np.repeat(np.tile(possible_inf_terms, in_repeat),out_repeat)\n",
    "out_repeat = out_repeat*len(possible_inf_terms)\n",
    "in_repeat = in_repeat//len(possible_soc_terms)\n",
    "ninth_socs = np.repeat(np.tile(possible_soc_terms, in_repeat),out_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 2\n",
      "0 0 4\n",
      "0 0 6\n",
      "0 0 8\n",
      "0 0 10\n",
      "0 0 12\n",
      "0 0 14\n",
      "0 0 16\n",
      "0 0 18\n",
      "0 2 0\n",
      "0 2 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t2 \u001b[38;5;129;01min\u001b[39;00m theta_to_test:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t3 \u001b[38;5;129;01min\u001b[39;00m theta_to_test:\n\u001b[1;32m----> 5\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_logloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfourth_thetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfifth_thetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43msixth_thetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseventh_costs\u001b[49m\u001b[43m,\u001b[49m\u001b[43meighth_infs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mninth_socs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_until_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m         all_output\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(t1,t2,t3)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_output = []\n",
    "for t1 in theta_to_test:\n",
    "    for t2 in theta_to_test:\n",
    "        for t3 in theta_to_test:\n",
    "            output = jax.vmap(compute_logloss,in_axes=(None,)*3+(0,)*6)(t1,t2,t3,fourth_thetas,fifth_thetas,sixth_thetas,seventh_costs,eighth_infs,ninth_socs).block_until_ready()\n",
    "            all_output.append(output)\n",
    "            print(t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output = np.array(all_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output = np.array(all_output)\n",
    "all_output = all_output.flatten()\n",
    "# save all_output to a file\n",
    "np.save('UK_flattened_output_big_eps.npy', all_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_output = all_output.reshape(len(theta_to_test),len(theta_to_test),len(theta_to_test),len(possible_soc_terms),len(possible_inf_terms),len(costs),len(theta_to_test),len(theta_to_test),len(theta_to_test)).transpose(0,1,2,8,7,6,5,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-4324.632 -3615.312\n",
      "-4303.101 -3619.4585\n",
      "-4290.9717 -3622.411\n",
      "-4294.791 -3624.4722\n",
      "-4308.218 -3625.9976\n",
      "-5152.9663 -3672.52\n",
      "-5112.2715 -3670.7334\n",
      "-5089.3447 -3670.5178\n",
      "-5075.5537 -3670.7263\n",
      "-5069.44 -3671.2114\n",
      "-6094.6553 -3703.5725\n",
      "-6044.421 -3701.9333\n",
      "-6016.3276 -3702.767\n",
      "-5999.4873 -3701.9702\n",
      "-5988.998 -3701.405\n",
      "-7062.5957 -3753.949\n",
      "-7008.8525 -3769.2195\n",
      "-6979.0547 -3771.3413\n",
      "-6966.913 -3769.417\n",
      "-7008.6724 -3763.311\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-4220.142 -3648.103\n",
      "-4201.9697 -3659.3066\n",
      "-4195.8496 -3663.6694\n",
      "-4196.4883 -3663.715\n",
      "-4201.1343 -3660.8994\n",
      "-4923.6816 -3674.3572\n",
      "-4891.9424 -3674.6611\n",
      "-4881.4507 -3674.4844\n",
      "-4882.4956 -3673.8408\n",
      "-4890.7104 -3673.3042\n",
      "-5814.414 -3704.1997\n",
      "-5775.1675 -3714.152\n",
      "-5762.089 -3716.3662\n",
      "-5763.3945 -3712.8418\n",
      "-5773.635 -3707.6987\n",
      "-6767.6143 -3766.0618\n",
      "-6726.537 -3752.4294\n",
      "-6712.8145 -3751.2769\n",
      "-6714.1846 -3753.3066\n",
      "-6724.9307 -3758.7803\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-4141.4863 -3664.0364\n",
      "-4135.393 -3667.4053\n",
      "-4133.9653 -3670.0083\n",
      "-4135.075 -3672.605\n",
      "-4138.1694 -3675.1396\n",
      "-4710.1763 -3671.6045\n",
      "-4695.3716 -3681.2725\n",
      "-4691.6104 -3686.041\n",
      "-4693.742 -3688.228\n",
      "-4700.379 -3691.142\n",
      "-5475.638 -3742.4229\n",
      "-5448.818 -3759.316\n",
      "-5444.6084 -3761.3896\n",
      "-5453.7373 -3755.4749\n",
      "-5472.4487 -3745.55\n",
      "-6399.4395 -3754.641\n",
      "-6367.757 -3766.275\n",
      "-6362.7246 -3768.0679\n",
      "-6373.619 -3763.1528\n",
      "-6395.7046 -3756.3652\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-3798.5068 -3798.5068\n",
      "-4166.9614 -3655.4622\n",
      "-4170.4634 -3656.6936\n",
      "-4167.9004 -3657.385\n",
      "-4161.4683 -3657.9607\n",
      "-4151.992 -3658.599\n",
      "-4723.4194 -3674.8882\n",
      "-4735.1294 -3681.8345\n",
      "-4730.0674 -3683.3325\n",
      "-4714.6074 -3682.2637\n",
      "-4691.0684 -3679.981\n",
      "-5279.4 -3758.6143\n",
      "-5296.9253 -3764.9363\n",
      "-5290.038 -3766.754\n",
      "-5268.523 -3769.311\n",
      "-5268.913 -3769.1978\n",
      "-6053.135 -3787.7083\n",
      "-6029.615 -3787.7207\n",
      "-6027.615 -3787.7393\n",
      "-6038.793 -3787.766\n",
      "-6059.9297 -3787.8057\n"
     ]
    }
   ],
   "source": [
    "# for cost_i in range(len(costs)):\n",
    "#     for inf_i in range(len(possible_inf_terms)):\n",
    "#         for soc_i in range(len(possible_soc_terms)):\n",
    "#            print(np.argmax(UK_output[:,:,:,:,:,:,cost_i,inf_i,soc_i]),np.max(UK_output[:,:,:,:,:,:,cost_i,inf_i,soc_i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
